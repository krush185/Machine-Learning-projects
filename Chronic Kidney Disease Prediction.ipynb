{"cells":[{"cell_type":"markdown","metadata":{"id":"NHQBo3XihPUm"},"source":["[internships.datalabs.info](https://internships.datalabs.info)\n","\n","\n","### Internship on \"Data Science\" at InfraBIM Techno Solutions\n","#### Project - Chronic Kidney Disease Prediction"]},{"cell_type":"markdown","metadata":{"id":"UrsSs3RLhPUq"},"source":["Name:   K Krushna Varshitha <br>\n","Email Id:  kkrushna185@gmail.com <br>\n","Date: 18-11-2023"]},{"cell_type":"markdown","metadata":{"id":"Hz36Y2XNhPUq"},"source":["### Problem Statement\n"]},{"cell_type":"markdown","metadata":{"id":"qDx8RNLRhPUr"},"source":["To classify patients as having chronic kidney disease or not using Artificial neural networks (ANN)."]},{"cell_type":"markdown","metadata":{"id":"IiWIDe-xhPUr"},"source":["## <div id=\"toc\">Table of Contents</div>\n","<ol>\n","<li><a href=\"#ImportLibraries\" style=\"text-decoration:none\">Import And Install Packages</a></li>\n","<li><a href=\"#LoadDataset\" style=\"text-decoration:none\">Load Dataset</a></li>\n","<li><a href=\"#EDA\" style=\"text-decoration:none\">Exploratory Data Analysis (EDA)</a></li>\n","</ol>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3SCtVh1hPUs"},"outputs":[],"source":["# import warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"Du0SgnXmhPUt"},"source":["#### <div id=\"ImportLibraries\">1. Installing and Importing the required packages <a href=\"#toc\" style=\"text-decoration:none\">[ Top ]</a></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Dh21C3cJNzB"},"outputs":[],"source":["%pip install keras\n","%pip install tensorflow\n","\n","#importing libraries\n","import glob\n","from __future__ import print_function\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","import numpy as np\n","import pandas as pd\n","from keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","import matplotlib.pyplot as plt\n","import keras as k"]},{"cell_type":"markdown","metadata":{"id":"R9R0xM-5hPUv"},"source":["#### <div id=\"LoadDataset\">2. Load Dataset <a href=\"#toc\" style=\"text-decoration:none\">[ Top ]</a></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bP8EUQNNhPUv"},"outputs":[],"source":["#loading the data\n","import pandas as pd\n","from google.colab import files\n","uploaded = files.upload()\n","\n","df = pd.read_csv('kidney_disease.csv')\n","\n","#printing first 5 rows\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"X-IEWOXDhPUw"},"source":["#### <div id=\"EDA\">3. Exploratory Data Analysis (EDA) <a href=\"#toc\" style=\"text-decoration:none\">[ Top ]</a></div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztHSdfzIhPUx"},"outputs":[],"source":["#getting the shape of the data\n","df.shape\n","\n","#creating a list of column names to keep\n","column_to_retain = ['sg', 'al', 'sc', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'classification']\n","\n","#dropping the columns that are not in column_to_retain\n","df = df.drop( [col for col in df.columns if not col in column_to_retain], axis = 1 )\n","\n","#dropping the rows with na or missing values\n","df = df.dropna(axis=0)\n","\n","#transformingthe non numeric data in columns\n","for column in df.columns:\n","  if df[column].dtype == np.number:\n","    continue\n","  df[column] = LabelEncoder().fit_transform( df[column] )\n","\n","#printing the first 5 rown in new cleaned datasets\n","df.head()\n","\n","#split the data into independent (X) data set (the features) and dependent (Y) data set (the target)\n","x = df.drop(['classification'], axis=1)\n","y = df['classification']\n","\n","#Feature scaling\n","x_scaler = MinMaxScaler()\n","x_scaler.fit(x)\n","column_names = x.columns\n","x[column_names] = x_scaler.transform(x)\n","\n","#split the data into 80% training and 20% testing and shuffle\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle = True)\n","\n","#building the model\n","model = Sequential()\n","model.add( Dense(256, input_dim = len(x.columns), kernel_initializer = k.initializers.random_normal(seed = 13), activation = 'relu') )\n","model.add( Dense(1, activation='hard_sigmoid') )\n","\n","#compiling the model\n","model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","\n","#training the model\n","history = model.fit(x_train, y_train, epochs = 2000, batch_size = x_train.shape[0])\n","\n","#saving the model\n","model.save('ckd.model')\n","\n","#visualizing the models loss and accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['loss'])\n","plt.title('model accuracy & loss')\n","plt.ylabel('accuracy & loss')\n","plt.xlabel('epoch')\n","\n","#getting the shape of training and testing data sets\n","print('shape of training data: ', x_train.shape)\n","print('shape of test data: ', x_test.shape)\n","\n","#showing the actual and predicted values\n","pred = model.predict(x_test)\n","pred = [1 if y>=0.5 else 0 for y in pred]\n","\n","print('original : {0}'.format(\", \".join(str(x) for x in y_test)))\n","print('Predicted : {0}'.format(\", \".join(str(x) for x in pred)))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
